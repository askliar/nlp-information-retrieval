{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "img_data = './data/img_data'\n",
    "text_data = './data/text_data'\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.remove('no')\n",
    "stop.update(['?', '\\'s', ',', '!', '.', '-', ':', '_', ''])\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-58e18748607d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Easy/IR_test_easy.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py-nlp1/lib/python3.5/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines)\u001b[0m\n\u001b[1;32m    352\u001b[0m         obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,\n\u001b[1;32m    353\u001b[0m                           \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                           date_unit).parse()\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py-nlp1/lib/python3.5/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py-nlp1/lib/python3.5/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 639\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "stem = True\n",
    "stopwords = True\n",
    "df = pd.read_json(os.path.join(text_data, 'Easy/IR_test_easy.json')).T.sort_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = df.apply(lambda x: pd.Series(x['dialog']),axis=1)\\\n",
    "        .stack()\\\n",
    "        .reset_index(level=1, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_result = s.apply(lambda q: \n",
    "                   (lambda x = q[0].split('?')[1].strip().lower(): x if x == 'yes' or x == 'no' else '')())\n",
    "q_result = q_result.reset_index(drop=True)\n",
    "q_bool = s.apply(lambda q: \n",
    "                 (lambda x = q[0].split('?')[1].strip(): True if x == 'yes' or x == 'no' else False)())\n",
    "s.name = 'question'\n",
    "q_result = pd.Series(q_result[q_bool.reset_index(drop=True)].reset_index(drop=True))\\\n",
    "                     .apply(lambda x: True if x == 'yes' else False)\n",
    "q_result.name = 'question_result'\n",
    "df = df.drop('dialog', axis=1).join(s)[q_bool].reset_index(drop=True)\\\n",
    "                              .join(q_result).dropna()\\\n",
    "                              .reset_index(drop= True).drop('img_list', axis=1).drop('target', axis=1)\n",
    "df.question = df.question.apply(lambda x: x[0])\n",
    "df.question = df.question.apply(lambda sentence: \n",
    "                                tuple(\n",
    "                                    [(lambda x: stemmer.stem(x) if stem else x)(i)\n",
    "                                     for i in word_tokenize(sentence.lower()) \n",
    "                                     if i not in stop or not stopwords]\n",
    "                                )\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>img_list</th>\n",
       "      <th>target_img_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a plate of broccoli, tomatoes, cheese and berr...</td>\n",
       "      <td>[81964, 185247, 298360, 286685, 70508, 239483,...</td>\n",
       "      <td>81964</td>\n",
       "      <td>(peopl, pictur, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a plate of broccoli, tomatoes, cheese and berr...</td>\n",
       "      <td>[81964, 185247, 298360, 286685, 70508, 239483,...</td>\n",
       "      <td>81964</td>\n",
       "      <td>(utensil, pictur, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a plate of broccoli, tomatoes, cheese and berr...</td>\n",
       "      <td>[81964, 185247, 298360, 286685, 70508, 239483,...</td>\n",
       "      <td>81964</td>\n",
       "      <td>(napkin, pictur, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a plate of broccoli, tomatoes, cheese and berr...</td>\n",
       "      <td>[81964, 185247, 298360, 286685, 70508, 239483,...</td>\n",
       "      <td>81964</td>\n",
       "      <td>(see, beverag, pictur, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a plate of broccoli, tomatoes, cheese and berr...</td>\n",
       "      <td>[81964, 185247, 298360, 286685, 70508, 239483,...</td>\n",
       "      <td>81964</td>\n",
       "      <td>(see, applianc, pictur, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a black jacket standing next to snowboard with...</td>\n",
       "      <td>[485550, 384916, 355462, 457587, 411225, 30546...</td>\n",
       "      <td>175410</td>\n",
       "      <td>(peopl, shot, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a group of skiers in a line skiing cross country</td>\n",
       "      <td>[471901, 212063, 109177, 425577, 194553, 53940...</td>\n",
       "      <td>81961</td>\n",
       "      <td>(back, toward, camera, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a group of skiers in a line skiing cross country</td>\n",
       "      <td>[471901, 212063, 109177, 425577, 194553, 53940...</td>\n",
       "      <td>81961</td>\n",
       "      <td>(see, other, photo, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a group of dogs laying on top of a bed</td>\n",
       "      <td>[214210, 346437, 475902, 111648, 468992, 44793...</td>\n",
       "      <td>111648</td>\n",
       "      <td>(peopl, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a group of dogs laying on top of a bed</td>\n",
       "      <td>[214210, 346437, 475902, 111648, 468992, 44793...</td>\n",
       "      <td>111648</td>\n",
       "      <td>(window, behind, couch, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a group of dogs laying on top of a bed</td>\n",
       "      <td>[214210, 346437, 475902, 111648, 468992, 44793...</td>\n",
       "      <td>111648</td>\n",
       "      <td>(couch, pattern, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a guy and a smiling lady standing by a big cake</td>\n",
       "      <td>[65616, 117918, 341963, 8789, 78674, 360020, 8...</td>\n",
       "      <td>65616</td>\n",
       "      <td>(tell, say, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a man is walking a white horse in a fenced-in ...</td>\n",
       "      <td>[125305, 302872, 164972, 168741, 546762, 53921...</td>\n",
       "      <td>164972</td>\n",
       "      <td>(hat, 1, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a man is walking a white horse in a fenced-in ...</td>\n",
       "      <td>[125305, 302872, 164972, 168741, 546762, 53921...</td>\n",
       "      <td>164972</td>\n",
       "      <td>(peopl, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a man is walking a white horse in a fenced-in ...</td>\n",
       "      <td>[125305, 302872, 164972, 168741, 546762, 53921...</td>\n",
       "      <td>164972</td>\n",
       "      <td>(spectat, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a man is walking a white horse in a fenced-in ...</td>\n",
       "      <td>[125305, 302872, 164972, 168741, 546762, 53921...</td>\n",
       "      <td>164972</td>\n",
       "      <td>(hors, visibl, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a man is walking a white horse in a fenced-in ...</td>\n",
       "      <td>[125305, 302872, 164972, 168741, 546762, 53921...</td>\n",
       "      <td>164972</td>\n",
       "      <td>(man, bald, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a man is walking a white horse in a fenced-in ...</td>\n",
       "      <td>[125305, 302872, 164972, 168741, 546762, 53921...</td>\n",
       "      <td>164972</td>\n",
       "      <td>(hors, saddl, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a plane on a runway about to take off</td>\n",
       "      <td>[309773, 378736, 381810, 396221, 117916, 38140...</td>\n",
       "      <td>175418</td>\n",
       "      <td>(commerci, plane, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a plane on a runway about to take off</td>\n",
       "      <td>[309773, 378736, 381810, 396221, 117916, 38140...</td>\n",
       "      <td>175418</td>\n",
       "      <td>(see, peopl, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a plane on a runway about to take off</td>\n",
       "      <td>[309773, 378736, 381810, 396221, 117916, 38140...</td>\n",
       "      <td>175418</td>\n",
       "      <td>(plane, write, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a plane on a runway about to take off</td>\n",
       "      <td>[309773, 378736, 381810, 396221, 117916, 38140...</td>\n",
       "      <td>175418</td>\n",
       "      <td>(cloud, sky, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a plane on a runway about to take off</td>\n",
       "      <td>[309773, 378736, 381810, 396221, 117916, 38140...</td>\n",
       "      <td>175418</td>\n",
       "      <td>(anyth, els, happen, photo, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a parking meter sitting on the side of a street</td>\n",
       "      <td>[440520, 11726, 558616, 20640, 400027, 532277,...</td>\n",
       "      <td>20640</td>\n",
       "      <td>(car, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>a parking meter sitting on the side of a street</td>\n",
       "      <td>[440520, 11726, 558616, 20640, 400027, 532277,...</td>\n",
       "      <td>20640</td>\n",
       "      <td>(car, park, next, meter, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a parking meter sitting on the side of a street</td>\n",
       "      <td>[440520, 11726, 558616, 20640, 400027, 532277,...</td>\n",
       "      <td>20640</td>\n",
       "      <td>(look, like, person, own, park, car, get, horr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a group of teddy bears in glass cases</td>\n",
       "      <td>[533545, 371313, 528466, 313951, 202964, 1224,...</td>\n",
       "      <td>427545</td>\n",
       "      <td>(differ, size, yes)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a group of teddy bears in glass cases</td>\n",
       "      <td>[533545, 371313, 528466, 313951, 202964, 1224,...</td>\n",
       "      <td>427545</td>\n",
       "      <td>(children, no)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              caption  \\\n",
       "0   a plate of broccoli, tomatoes, cheese and berr...   \n",
       "1   a plate of broccoli, tomatoes, cheese and berr...   \n",
       "2   a plate of broccoli, tomatoes, cheese and berr...   \n",
       "3   a plate of broccoli, tomatoes, cheese and berr...   \n",
       "4   a plate of broccoli, tomatoes, cheese and berr...   \n",
       "5   a black jacket standing next to snowboard with...   \n",
       "6    a group of skiers in a line skiing cross country   \n",
       "7    a group of skiers in a line skiing cross country   \n",
       "8              a group of dogs laying on top of a bed   \n",
       "9              a group of dogs laying on top of a bed   \n",
       "10             a group of dogs laying on top of a bed   \n",
       "11    a guy and a smiling lady standing by a big cake   \n",
       "12  a man is walking a white horse in a fenced-in ...   \n",
       "13  a man is walking a white horse in a fenced-in ...   \n",
       "14  a man is walking a white horse in a fenced-in ...   \n",
       "15  a man is walking a white horse in a fenced-in ...   \n",
       "16  a man is walking a white horse in a fenced-in ...   \n",
       "17  a man is walking a white horse in a fenced-in ...   \n",
       "18              a plane on a runway about to take off   \n",
       "19              a plane on a runway about to take off   \n",
       "20              a plane on a runway about to take off   \n",
       "21              a plane on a runway about to take off   \n",
       "22              a plane on a runway about to take off   \n",
       "23    a parking meter sitting on the side of a street   \n",
       "24    a parking meter sitting on the side of a street   \n",
       "25    a parking meter sitting on the side of a street   \n",
       "26              a group of teddy bears in glass cases   \n",
       "27              a group of teddy bears in glass cases   \n",
       "\n",
       "                                             img_list target_img_id  \\\n",
       "0   [81964, 185247, 298360, 286685, 70508, 239483,...         81964   \n",
       "1   [81964, 185247, 298360, 286685, 70508, 239483,...         81964   \n",
       "2   [81964, 185247, 298360, 286685, 70508, 239483,...         81964   \n",
       "3   [81964, 185247, 298360, 286685, 70508, 239483,...         81964   \n",
       "4   [81964, 185247, 298360, 286685, 70508, 239483,...         81964   \n",
       "5   [485550, 384916, 355462, 457587, 411225, 30546...        175410   \n",
       "6   [471901, 212063, 109177, 425577, 194553, 53940...         81961   \n",
       "7   [471901, 212063, 109177, 425577, 194553, 53940...         81961   \n",
       "8   [214210, 346437, 475902, 111648, 468992, 44793...        111648   \n",
       "9   [214210, 346437, 475902, 111648, 468992, 44793...        111648   \n",
       "10  [214210, 346437, 475902, 111648, 468992, 44793...        111648   \n",
       "11  [65616, 117918, 341963, 8789, 78674, 360020, 8...         65616   \n",
       "12  [125305, 302872, 164972, 168741, 546762, 53921...        164972   \n",
       "13  [125305, 302872, 164972, 168741, 546762, 53921...        164972   \n",
       "14  [125305, 302872, 164972, 168741, 546762, 53921...        164972   \n",
       "15  [125305, 302872, 164972, 168741, 546762, 53921...        164972   \n",
       "16  [125305, 302872, 164972, 168741, 546762, 53921...        164972   \n",
       "17  [125305, 302872, 164972, 168741, 546762, 53921...        164972   \n",
       "18  [309773, 378736, 381810, 396221, 117916, 38140...        175418   \n",
       "19  [309773, 378736, 381810, 396221, 117916, 38140...        175418   \n",
       "20  [309773, 378736, 381810, 396221, 117916, 38140...        175418   \n",
       "21  [309773, 378736, 381810, 396221, 117916, 38140...        175418   \n",
       "22  [309773, 378736, 381810, 396221, 117916, 38140...        175418   \n",
       "23  [440520, 11726, 558616, 20640, 400027, 532277,...         20640   \n",
       "24  [440520, 11726, 558616, 20640, 400027, 532277,...         20640   \n",
       "25  [440520, 11726, 558616, 20640, 400027, 532277,...         20640   \n",
       "26  [533545, 371313, 528466, 313951, 202964, 1224,...        427545   \n",
       "27  [533545, 371313, 528466, 313951, 202964, 1224,...        427545   \n",
       "\n",
       "                                             question  question_result  \n",
       "0                                 (peopl, pictur, no)            False  \n",
       "1                              (utensil, pictur, yes)             True  \n",
       "2                                (napkin, pictur, no)            False  \n",
       "3                          (see, beverag, pictur, no)            False  \n",
       "4                         (see, applianc, pictur, no)            False  \n",
       "5                                   (peopl, shot, no)            False  \n",
       "6                         (back, toward, camera, yes)             True  \n",
       "7                            (see, other, photo, yes)             True  \n",
       "8                                         (peopl, no)            False  \n",
       "9                         (window, behind, couch, no)            False  \n",
       "10                               (couch, pattern, no)            False  \n",
       "11                                    (tell, say, no)            False  \n",
       "12                                       (hat, 1, no)            False  \n",
       "13                                       (peopl, yes)             True  \n",
       "14                                     (spectat, yes)             True  \n",
       "15                                 (hors, visibl, no)            False  \n",
       "16                                   (man, bald, yes)             True  \n",
       "17                                 (hors, saddl, yes)             True  \n",
       "18                             (commerci, plane, yes)             True  \n",
       "19                                   (see, peopl, no)            False  \n",
       "20                                (plane, write, yes)             True  \n",
       "21                                   (cloud, sky, no)            False  \n",
       "22                    (anyth, els, happen, photo, no)            False  \n",
       "23                                         (car, yes)             True  \n",
       "24                      (car, park, next, meter, yes)             True  \n",
       "25  (look, like, person, own, park, car, get, horr...            False  \n",
       "26                                (differ, size, yes)             True  \n",
       "27                                     (children, no)            False  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(text_data, 'Easy/IR_train_easy.json')).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.caption = df.caption.\\\n",
    "                apply(lambda sentence: tuple([stemmer.stem(i) for i in word_tokenize(sentence.lower()) if i not in stop]))\n",
    "caption_df = df[['caption', 'target_img_id']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = df.apply(lambda x: pd.Series(x['dialog']),axis=1)\\\n",
    "            .stack()\\\n",
    "            .reset_index(level=1, drop=True)\n",
    "q_bool = s.apply(lambda q: (lambda x = q[0].split('?')[1].strip(): True if x == 'yes' or x == 'no' else False)())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = df.apply(lambda x: pd.Series(x['dialog']),axis=1)\\\n",
    "            .stack()\\\n",
    "            .reset_index(level=1, drop=True)\n",
    "q_result = s.apply(lambda q: (lambda x = q[0].split('?')[1].strip().lower(): x if x == 'yes' or x == 'no' else '')())\n",
    "q_result = q_result.reset_index(drop=True)\n",
    "q_bool = s.apply(lambda q: (lambda x = q[0].split('?')[1].strip(): True if x == 'yes' or x == 'no' else False)())\n",
    "s.name = 'question'\n",
    "q_result = pd.Series(q_result[q_bool.reset_index(drop=True)].reset_index(drop=True))#[q_bool]\n",
    "q_result.name = 'question_result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('dialog', axis=1).join(s)[q_bool].reset_index(drop=True)\\\n",
    "     .join(q_result).dropna().reset_index(drop= True).drop('img_list', axis=1).drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.question = df.question.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.question = df.question.\\\n",
    "                apply(lambda sentence: tuple([stemmer.stem(i) for i in word_tokenize(sentence.lower()) if i not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_df = df[['question', 'question_result', 'target_img_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7ed0097d7e9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, complexity, captions, img_feat_file = 'IR_image_features.h5', \n",
    "                 img_map_file = 'IR_img_features2id.json', stem = True, stopwords = True,\n",
    "                normalize = True):\n",
    "        csv_file = '{}/IR_train_{}.json'.format(complexity.capitalize(), complexity)\n",
    "        csv_path = os.path.join(text_data, csv_file)\n",
    "        self.captions = captions\n",
    "        if captions:\n",
    "            self.df = self.preprocess_captions(csv_path, stem, stopwords)\n",
    "        else:\n",
    "            self.df = self.preprocess_questions(csv_path, stem, stopwords)\n",
    "            \n",
    "        self.img_features, self.mean, self.std, self.visual_feat_mapping = self.load_image_data(img_feat_file, img_map_file)\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 0]\n",
    "        img_id = self.df.iloc[idx, 1]\n",
    "        h5_id = self.visual_feat_mapping[str(img_id)]\n",
    "        img_feat = self.img_features[h5_id]\n",
    "        if self.captions:\n",
    "            target = True\n",
    "        else:\n",
    "            target = self.df.iloc[idx, 2]\n",
    "        # join text for batch processing (otherwise every words gets in a different tuple)\n",
    "        sample = {'text': ' '.join(text), 'img_features': img_feat, 'target': target}\n",
    "        return sample\n",
    "    \n",
    "    def preprocess_captions(self, csv_path, stem, stopwords):\n",
    "        df = pd.read_json(csv_path).T.sort_index()\n",
    "        df.caption = df.caption.apply(lambda sentence: \n",
    "                                tuple(\n",
    "                                    [(lambda x: stemmer.stem(x) if stem else x)(i)\n",
    "                                     for i in word_tokenize(sentence.lower()) \n",
    "                                     if i not in stop or not stopwords]\n",
    "                                )\n",
    "                               )\n",
    "        return df[['caption', 'target_img_id']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    def preprocess_questions(self, csv_path, stem, stopwords):\n",
    "        # TODO: Remove head after testing\n",
    "        df = pd.read_json(csv_path).T.sort_index().head(50)\n",
    "        s = df.apply(lambda x: pd.Series(x['dialog']),axis=1)\\\n",
    "                .stack()\\\n",
    "                .reset_index(level=1, drop=True)\n",
    "        q_result = s.apply(lambda q: \n",
    "                           (lambda x = q[0].split('?')[1].strip().lower(): x if x == 'yes' or x == 'no' else '')())\n",
    "        q_result = q_result.reset_index(drop=True)\n",
    "        q_bool = s.apply(lambda q: \n",
    "                         (lambda x = q[0].split('?')[1].strip().lower(): True if x == 'yes' or x == 'no' else False)())\n",
    "        s.name = 'question'\n",
    "        q_result = pd.Series(q_result[q_bool.reset_index(drop=True)]\\\n",
    "                             .reset_index(drop=True))\\\n",
    "                             .apply(lambda x: 1 if x == 'yes' else -1)\n",
    "        q_result.name = 'question_result'\n",
    "        df = df.drop('dialog', axis=1).join(s)[q_bool].reset_index(drop=True)\\\n",
    "                                      .join(q_result).dropna()\\\n",
    "                                      .reset_index(drop= True).drop('img_list', axis=1).drop('target', axis=1)\n",
    "        df.question = df.question.apply(lambda x: x[0])\n",
    "        df.question = df.question.apply(lambda sentence: \n",
    "                                tuple(\n",
    "                                    [(lambda x: stemmer.stem(x) if stem else x)(i)\n",
    "                                     for i in word_tokenize(sentence.lower()) \n",
    "                                     if i not in stop or not stopwords]\n",
    "                                )\n",
    "                               )\n",
    "        df_augmented = df.copy()\n",
    "        df_augmented.question_result = -df_augmented.question_result\n",
    "        df_augmented.question = df_augmented.question.\\\n",
    "                                apply(lambda sent: sent[:-1] + ('yes', ) \n",
    "                                      if sent[-1] == 'no' else sent[:-1] + ('no', ))\n",
    "        df = df.append(df_augmented, ignore_index = True)\n",
    "        return df[['question', 'target_img_id', 'question_result']]\n",
    "    \n",
    "    def load_image_data(self, img_feat_file, img_map_file):\n",
    "        img_features = np.asarray(h5py.File(os.path.join(img_data, img_feat_file), 'r')['img_features'])\n",
    "        with open(os.path.join(img_data, img_map_file), 'r') as f:\n",
    "             visual_feat_mapping = json.load(f)['IR_imgid2id']\n",
    "        mean = img_features.mean(axis=0)\n",
    "        std = img_features.std(axis=0)\n",
    "        img_features = (img_features - mean)/std\n",
    "        return img_features, mean, std, visual_feat_mapping\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_captions = TrainDataSet(complexity = 'easy', captions = True)\n",
    "data_train_questions = TrainDataSet(complexity = 'easy', captions = False)\n",
    "\n",
    "# data_val_captions = TextImageDataSet(split = 'val',  complexity = 'easy', captions = False)\n",
    "# data_val_questions = TextImageDataSet(split = 'val',  complexity = 'easy', captions = True)\n",
    "\n",
    "# data_test_captions = TextImageDataSet(split = 'test',  complexity = 'easy', captions = False)\n",
    "# data_test_questions = TextImageDataSet(split = 'test',  complexity = 'easy', captions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions_batch_size = 128\n",
    "questions_batch_size = 512\n",
    "\n",
    "dataloader_train_captions = DataLoader(data_train_captions, batch_size=captions_batch_size,\n",
    "                        shuffle=True, num_workers=4)\n",
    "dataloader_train_questions = DataLoader(data_train_questions, batch_size=questions_batch_size,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "# dataloader_val_captions = DataLoader(data_val_captions, batch_size=1000,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "# dataloader_val_questions = DataLoader(data_val_questions, batch_size=1000,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "\n",
    "# dataloader_test_captions = DataLoader(data_test_captions, batch_size=1000,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "# dataloader_test_questions = DataLoader(data_test_questions, batch_size=1000,\n",
    "#                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(caption_dataset, question_dataset, dictionary):\n",
    "    captions = list(caption_dataset.df.caption)\n",
    "    questions = list(question_dataset.df.question)\n",
    "    all_sentences = captions + questions\n",
    "    _ = [dictionary[word] for sentence in all_sentences for word in sentence]\n",
    "    return dictionary\n",
    "\n",
    "def preprocess_sentences(sentences, dictionary):\n",
    "    max_len = 0\n",
    "    resulting_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.split(' ')\n",
    "        max_len = max(max_len, len(sentence))\n",
    "        resulting_sentences.append([dictionary[word] for word in sentence])\n",
    "    resulting_sentences = [sentence + ([UNK] * (max_len - len(sentence))) for sentence in resulting_sentences]\n",
    "    return torch.LongTensor(resulting_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Functions to read in the corpus\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "UNK = w2i[\"<unk>\"]\n",
    "\n",
    "w2i = defaultdict(lambda: UNK, \n",
    "                  read_dataset(data_train_captions, data_train_questions, w2i))\n",
    "\n",
    "nwords = len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW (\n",
      "  (embeddings): Embedding(7683, 2048)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, img_feat_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, img_feat_size)\n",
    "        \n",
    "    def forward(self, input_text):\n",
    "        input_text = input_text.view(input_text.size(0), -1)\n",
    "        x = self.embeddings(input_text)\n",
    "        x = torch.sum(x, 1)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = CBOW(nwords, 64, 2048)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train(epoch, model, dataloader, batch_size = 128, cuda = False):\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for idx, sample in enumerate(dataloader):\n",
    "        text_data = preprocess_sentences(sample['text'], w2i)\n",
    "        img_feat = sample['img_features'] \n",
    "        target = sample['target'].float()\n",
    "        if cuda:\n",
    "            text_data, img_feat, target = text_data.cuda(), img_feat.cuda(), target.cuda()\n",
    "        text_data, img_feat, target = Variable(text_data), Variable(img_feat), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text_data)\n",
    "        loss = torch.sum(target * F.pairwise_distance(output, img_feat).view(-1))\n",
    "        batch_loss =  loss/target.size(0)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "    train_loss /= len(dataloader.dataset)\n",
    "    print('\\nTrain epoch: {} Average loss: {:.4f}\\n'.format(\n",
    "        epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, batch_size = 128, cuda = False):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/andrewsklyar/miniconda3/envs/py-nlp1/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-11a1db180655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     train(epoch, model, dataloader_train_captions, captions_batch_size, \n\u001b[0;32m----> 6\u001b[0;31m           cuda = torch.cuda.is_available())\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time taken: {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-6ad159f0d484>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, dataloader, batch_size, cuda)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py-nlp1/lib/python3.5/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    start = time.time()\n",
    "    train(epoch, model, dataloader_train_captions, captions_batch_size, \n",
    "          cuda = torch.cuda.is_available())\n",
    "    train(epoch, model, dataloader_train_questions, questions_batch_size, \n",
    "          cuda = torch.cuda.is_available())\n",
    "    print('Time taken: {}\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "DEBUG = True\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "captions_batch_size = 128\n",
    "questions_batch_size = 512\n",
    "\n",
    "img_data = './data/img_data'\n",
    "text_data = './data/text_data'\n",
    "img_feat_file = 'IR_image_features.h5',\n",
    "img_map_file = 'IR_img_features2id.json',\n",
    "complexity = 'easy'\n",
    "\n",
    "json_train_file = os.path.join(text_data,\n",
    "                               '{}/IR_train_{}.json'.format(complexity.capitalize(), complexity)\n",
    "                               )\n",
    "pickle_captions_train_file = os.path.join(text_data,\n",
    "                                          '{}/IR_train_{}_captions.pkl'.format(complexity.capitalize(), complexity)\n",
    "                                          )\n",
    "pickle_questions_train_file = os.path.join(text_data,\n",
    "                                           '{}/IR_train_{}_questions.pkl'.format(complexity.capitalize(), complexity)\n",
    "                                           )\n",
    "\n",
    "pickle_file_exists = os.path.isfile(pickle_captions_train_file) and os.path.isfile(pickle_questions_train_file)\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.remove('no')\n",
    "stop.update(['?', '\\'s', ',', '!', '.', '-', ':', '_', ''])\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stem = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file = '{}/IR_{}_{}.json'.format(complexity.capitalize(), split, complexity)\n",
    "csv_path = os.path.join(text_data, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(csv_path).T.sort_index().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (small, dog, pink, shirt, sit, gym, remot)\n",
       "1    (hard, wood, floor, kitchen, black, applianc)\n",
       "2                 (skii, slope, skier, ski, slope)\n",
       "3          (man, hors, drawn, carriag, red, light)\n",
       "4             (dog, bandana, glass, stare, someth)\n",
       "Name: caption, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.caption = df.caption.apply(lambda sentence:\n",
    "        tuple(\n",
    "            [(lambda x: stemmer.stem(x) if stem else x)(word)\n",
    "             for word in word_tokenize(sentence.lower())\n",
    "             if word not in stop or not stopwords]\n",
    "        )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>dialog</th>\n",
       "      <th>img_list</th>\n",
       "      <th>target</th>\n",
       "      <th>target_img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a small dog with a pink shirt sitting gym a re...</td>\n",
       "      <td>[[is the dog inside a gym ? no], [what kind of...</td>\n",
       "      <td>[298299, 359302, 442687, 289895, 66976, 51606,...</td>\n",
       "      <td>4</td>\n",
       "      <td>66976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a hard wood floor kitchen with black appliances</td>\n",
       "      <td>[[can you see the stove ? yes], [how about the...</td>\n",
       "      <td>[576290, 258000, 53232, 335107, 112604, 317458...</td>\n",
       "      <td>1</td>\n",
       "      <td>258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a skii slope with skiers skiing down the slope</td>\n",
       "      <td>[[how many skiers ? there are 2], [male or fem...</td>\n",
       "      <td>[578041, 354874, 553671, 258753, 28093, 255500...</td>\n",
       "      <td>1</td>\n",
       "      <td>354874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a man in a horse drawn carriage at a red light</td>\n",
       "      <td>[[are they on street ? yes], [do you see any p...</td>\n",
       "      <td>[64616, 268317, 48288, 373101, 465045, 422026,...</td>\n",
       "      <td>8</td>\n",
       "      <td>421024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a dog with bandana and glasses staring at some...</td>\n",
       "      <td>[[what color is the bandana ? blue with black ...</td>\n",
       "      <td>[126296, 62231, 153888, 175121, 292574, 580837...</td>\n",
       "      <td>7</td>\n",
       "      <td>132331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0  a small dog with a pink shirt sitting gym a re...   \n",
       "1    a hard wood floor kitchen with black appliances   \n",
       "2     a skii slope with skiers skiing down the slope   \n",
       "3     a man in a horse drawn carriage at a red light   \n",
       "4  a dog with bandana and glasses staring at some...   \n",
       "\n",
       "                                              dialog  \\\n",
       "0  [[is the dog inside a gym ? no], [what kind of...   \n",
       "1  [[can you see the stove ? yes], [how about the...   \n",
       "2  [[how many skiers ? there are 2], [male or fem...   \n",
       "3  [[are they on street ? yes], [do you see any p...   \n",
       "4  [[what color is the bandana ? blue with black ...   \n",
       "\n",
       "                                            img_list target target_img_id  \n",
       "0  [298299, 359302, 442687, 289895, 66976, 51606,...      4         66976  \n",
       "1  [576290, 258000, 53232, 335107, 112604, 317458...      1        258000  \n",
       "2  [578041, 354874, 553671, 258753, 28093, 255500...      1        354874  \n",
       "3  [64616, 268317, 48288, 373101, 465045, 422026,...      8        421024  \n",
       "4  [126296, 62231, 153888, 175121, 292574, 580837...      7        132331  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text2int(self, text, vocab):\n",
    "    return [vocab[word] for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def questions2int(questions, vocab):\n",
    "    questions = [sentence for sentences in text for sentence in questions]\n",
    "    questions_int = []\n",
    "    for question in questions:\n",
    "        answer = question.split('?')[1].strip().lower()\n",
    "        is_binary = answer == 'yes' or answer == 'no'\n",
    "        if is_binary:\n",
    "            processed_question = tuple([(lambda x: stemmer.stem(x) if stem else x)(word)\n",
    "                                        for word in word_tokenize(question.lower())\n",
    "                                        if word not in stop or not stopwords]\n",
    "                                      )\n",
    "            questions = text2int(processed_question)\n",
    "            questions_int.append(questions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>dialog</th>\n",
       "      <th>img_list</th>\n",
       "      <th>target</th>\n",
       "      <th>target_img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a small dog with a pink shirt sitting gym a re...</td>\n",
       "      <td>[[is the dog inside a gym ? no], [what kind of...</td>\n",
       "      <td>[298299, 359302, 442687, 289895, 66976, 51606,...</td>\n",
       "      <td>4</td>\n",
       "      <td>66976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a hard wood floor kitchen with black appliances</td>\n",
       "      <td>[[can you see the stove ? yes], [how about the...</td>\n",
       "      <td>[576290, 258000, 53232, 335107, 112604, 317458...</td>\n",
       "      <td>1</td>\n",
       "      <td>258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a skii slope with skiers skiing down the slope</td>\n",
       "      <td>[[how many skiers ? there are 2], [male or fem...</td>\n",
       "      <td>[578041, 354874, 553671, 258753, 28093, 255500...</td>\n",
       "      <td>1</td>\n",
       "      <td>354874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a man in a horse drawn carriage at a red light</td>\n",
       "      <td>[[are they on street ? yes], [do you see any p...</td>\n",
       "      <td>[64616, 268317, 48288, 373101, 465045, 422026,...</td>\n",
       "      <td>8</td>\n",
       "      <td>421024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a dog with bandana and glasses staring at some...</td>\n",
       "      <td>[[what color is the bandana ? blue with black ...</td>\n",
       "      <td>[126296, 62231, 153888, 175121, 292574, 580837...</td>\n",
       "      <td>7</td>\n",
       "      <td>132331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0  a small dog with a pink shirt sitting gym a re...   \n",
       "1    a hard wood floor kitchen with black appliances   \n",
       "2     a skii slope with skiers skiing down the slope   \n",
       "3     a man in a horse drawn carriage at a red light   \n",
       "4  a dog with bandana and glasses staring at some...   \n",
       "\n",
       "                                              dialog  \\\n",
       "0  [[is the dog inside a gym ? no], [what kind of...   \n",
       "1  [[can you see the stove ? yes], [how about the...   \n",
       "2  [[how many skiers ? there are 2], [male or fem...   \n",
       "3  [[are they on street ? yes], [do you see any p...   \n",
       "4  [[what color is the bandana ? blue with black ...   \n",
       "\n",
       "                                            img_list target target_img_id  \n",
       "0  [298299, 359302, 442687, 289895, 66976, 51606,...      4         66976  \n",
       "1  [576290, 258000, 53232, 335107, 112604, 317458...      1        258000  \n",
       "2  [578041, 354874, 553671, 258753, 28093, 255500...      1        354874  \n",
       "3  [64616, 268317, 48288, 373101, 465045, 422026,...      8        421024  \n",
       "4  [126296, 62231, 153888, 175121, 292574, 580837...      7        132331  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dialog.apply(lambda arr:\n",
    "               for sentence in arr:)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py-nlp1]",
   "language": "python",
   "name": "conda-env-py-nlp1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
