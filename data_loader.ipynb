{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "img_data = './data/img_data'\n",
    "text_data = './data/text_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(text_data, 'Easy/IR_train_easy.json'))\n",
    "# df = df.T.sort_index()\n",
    "# df.dialog = df.dialog.apply(lambda arr: ' '.join([sent for item in arr for sent in item]))\n",
    "# df['all_words'] = df[['caption', 'dialog']].apply(lambda x: x[0] + ' ' + x[1], axis = 1)\n",
    "# df = df[['caption', 'dialog', 'all_words', 'img_list', 'target', 'target_img_id']]\n",
    "# s = df.apply(lambda x: pd.Series(x['img_list']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "# s.name = 'img_id'\n",
    "# df = df.drop('img_list', axis=1).join(s).drop('target', axis=1).reset_index(drop= True)\n",
    "# df['target_onehot'] = np.where(df['target_img_id'] == df['img_id'], 1, 0)\n",
    "# s = []\n",
    "# for img_id in df.img_id.iteritems():\n",
    "#     h5_id = visual_feat_mapping[str(img_id[1])]\n",
    "#     img_feat = img_features[h5_id]\n",
    "#     s.append(img_feat)\n",
    "\n",
    "# df['img_feat'] = pd.Series(s)\n",
    "# df[['all_words', 'img_feat', 'target_onehot']].to_csv('./data/train_data_easy_bow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_val = pd.read_json(os.path.join(text_data, 'Easy/IR_val_easy.json'))\n",
    "# df_val = df_val.T.sort_index()\n",
    "# df_val.dialog = df_val.dialog.apply(lambda arr: ' '.join([sent for item in arr for sent in item]))\n",
    "# df_val['all_words'] = df_val[['caption', 'dialog']].apply(lambda x: x[0] + ' ' + x[1], axis = 1)\n",
    "# df_val = df_val[['caption', 'dialog', 'all_words', 'img_list', 'target', 'target_img_id']]\n",
    "# s = df_val.apply(lambda x: pd.Series(x['img_list']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "# s.name = 'img_id'\n",
    "# df_val = df_val.drop('img_list', axis=1).join(s).drop('target', axis=1).reset_index(drop= True)\n",
    "# df_val['target_onehot'] = np.where(df_val['target_img_id'] == df_val['img_id'], 1, 0)\n",
    "# s = []\n",
    "# for img_id in df_val.img_id.iteritems():\n",
    "#     h5_id = visual_feat_mapping[str(img_id[1])]\n",
    "#     img_feat = img_features[h5_id]\n",
    "#     s.append(img_feat)\n",
    "\n",
    "# df_val['img_feat'] = pd.Series(s)\n",
    "# df_val[['all_words', 'img_feat', 'target_onehot']].to_csv('./data/val_data_easy_bow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_test = pd.read_json(os.path.join(text_data, 'Easy/IR_test_easy.json'))\n",
    "# df_test = df_test.T.sort_index()\n",
    "# df_test.dialog = df_test.dialog.apply(lambda arr: ' '.join([sent for item in arr for sent in item]))\n",
    "# df_test['all_words'] = df_test[['caption', 'dialog']].apply(lambda x: x[0] + ' ' + x[1], axis = 1)\n",
    "# df_test = df_test[['caption', 'dialog', 'all_words', 'img_list', 'target', 'target_img_id']]\n",
    "# s = df_test.apply(lambda x: pd.Series(x['img_list']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "# s.name = 'img_id'\n",
    "# df_test = df_test.drop('img_list', axis=1).join(s).drop('target', axis=1).reset_index(drop= True)\n",
    "# df_test['target_onehot'] = np.where(df_test['target_img_id'] == df_test['img_id'], 1, 0)\n",
    "# s = []\n",
    "# for img_id in df_test.img_id.iteritems():\n",
    "#     h5_id = visual_feat_mapping[str(img_id[1])]\n",
    "#     img_feat = img_features[h5_id]\n",
    "#     s.append(img_feat)\n",
    "\n",
    "# df_test['img_feat'] = pd.Series(s)\n",
    "# df_test[['all_words', 'img_feat', 'target_onehot']].to_csv('./data/test_data_easy_bowf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train easy\n",
      "train hard\n",
      "val easy\n",
      "val hard\n",
      "test easy\n",
      "test hard\n"
     ]
    }
   ],
   "source": [
    "for data in ['train', 'val', 'test']:\n",
    "    for complexity in ['easy', 'hard']:\n",
    "        print(data, complexity)\n",
    "        df = pd.read_json(os.path.join(text_data, '{0}/IR_{1}_{2}.json'\\\n",
    "                                       .format(complexity.capitalize(), data, complexity)))\n",
    "        df = df.T.sort_index()\n",
    "        df.dialog = df.dialog\\\n",
    "            .apply(lambda arr: ' \\n '.join([sent for item in arr for sent in item]))\n",
    "        df['all_words'] = df[['caption', 'dialog']]\\\n",
    "            .apply(lambda x: x[0] + ' \\n ' + x[1], axis = 1)\n",
    "        df = df[['caption', 'dialog', 'all_words', 'img_list', 'target', 'target_img_id']]\n",
    "        s = df.apply(lambda x: pd.Series(x['img_list']),axis=1)\\\n",
    "            .stack()\\\n",
    "            .reset_index(level=1, drop=True)\n",
    "        s.name = 'img_id'\n",
    "        df = df.drop('img_list', axis=1).join(s).drop('target', axis=1).reset_index(drop= True)\n",
    "        df['target_onehot'] = np.where(df['target_img_id'] == df['img_id'], 1, 0)\n",
    "        \n",
    "        df[['all_words', 'img_id', 'target_onehot']].to_csv('./data/{0}_data_{1}_bow.csv'\\\n",
    "                                                             .format(data, complexity), \n",
    "                                                              index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a person that is laying next to a dog \\n is this a child or adult ? adult \\n male or female ? male \\n are they inside or outside ? inside \\n are they laying on the floor ? yes, but there is a blanket in between them and the floor \\n is the floor carpeted or wooden ? it is tile \\n what color is the blanket ? red and white \\n what color is the tile ? orange red \\n what breed is the dog ? boxer \\n does the dog look healthy and happy ? yes \\n what color is the dog ? tan'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/train_data_easy_bow.csv').all_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class ImageTextDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "        \"\"\"\n",
    "        self.imagetext_frame = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagetext_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.imagetext_frame.iloc[idx, 0].split(' \\n ')\n",
    "        img_id = self.imagetext_frame.iloc[idx, 1]\n",
    "        target = self.imagetext_frame.iloc[idx, 2]\n",
    "        h5_id = visual_feat_mapping[str(img_id)]\n",
    "        img_feat = img_features[h5_id]\n",
    "        sample = {'text': text, 'img_features': img_feat, 'target': target}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = ImageTextDataSet(csv_file='./data/train_data_easy_bow.csv')\n",
    "dataloader_train = DataLoader(data_train, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "data_val = ImageTextDataSet(csv_file='./data/val_data_easy_bow.csv')\n",
    "dataloader_val = DataLoader(data_val, num_workers=4)\n",
    "\n",
    "data_test = ImageTextDataSet(csv_file='./data/test_data_easy_bow.csv')\n",
    "dataloader_test = DataLoader(data_test, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "CBOW\n",
    "\n",
    "Based on Graham Neubig's DyNet code examples:\n",
    "  https://github.com/neubig/nn4nlp2017-code\n",
    "  http://phontron.com/class/nn4nlp2017/\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Functions to read in the corpus\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "UNK = w2i[\"<unk>\"]\n",
    "\n",
    "def read_dataset(dataloader):\n",
    "    for batch in dataloader:\n",
    "        text = batch['text']\n",
    "        for sentences in text:\n",
    "            for sentence in sentences:\n",
    "                resulting_sentence = sentence.lower().strip()\n",
    "                yield ([w2i[x] for x in resulting_sentence.split(\" \")])\n",
    "\n",
    "# Read in the data\n",
    "train = list(read_dataset(dataloader_train))\n",
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "val = list(read_dataset(dataloader_val))\n",
    "test = list(read_dataset(dataloader_test))\n",
    "\n",
    "nwords = len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a person that is laying next to a dog ',\n",
       " ' is this a child or adult ? adult ',\n",
       " ' male or female ? male ',\n",
       " ' are they inside or outside ? inside ',\n",
       " ' are they laying on the floor ? yes, but there is a blanket in between them and the floor ',\n",
       " ' is the floor carpeted or wooden ? it is tile ',\n",
       " ' what color is the blanket ? red and white ',\n",
       " ' what color is the tile ? orange red ',\n",
       " ' what breed is the dog ? boxer ',\n",
       " ' does the dog look healthy and happy ? yes ',\n",
       " ' what color is the dog ? tan']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/train_data_easy_bow.csv').all_words[0].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': [('a giraffe eating green leaves in the forest', 'a bunch of boys wearing the same colors supporting their team', 'a orange on a plate on a table', \"the top of the heads of a pair of zebra's\"), ('how is weather ? sky is white or grayish, overcast', 'how many boys have an you seen ? 7 with visible faces', 'any people there ? no', 'is this in color ? yes'), ('is there any other animals ? no', \"how old do they look ? most look in their 20's and 1 is an older guy\", 'is the orange peeled ? no', 'is this a close up ? yes'), ('is there any trees ? yes, lots behind in background', 'what ethnicity are they ? white and hispanic from what i can tell', 'what color is the plate ? white', 'can you see any trees ? no'), ('is it in field ? sort of, but grass is short', 'what colors are they wearing ? red and white', 'is it a glass plate ? yes', 'can you see any grass ? no'), ('is there path ? not that i can see, no', \"can you tell what sport it is ? not really, but i'd guess basketball\", 'is there only 1 orange ? 1', 'can you see the sky ? no'), ('is there any flowers ? nope', \"are they playing right now ? seems like there's a game in progress but can only see spectators\", 'is there a tablecloth on the table ? no', 'is the image watermarked ? yes'), ('can you see ground ? yes, grass below it', 'how many spectators are there ? about 15', 'is the table made of wood ? yes', \"can you see the zebras' eyes ? yes\"), ('is there fence ? i think so 1 made of wood', \"what color is the court ? can't see it\", 'light or dark wood ? dark', 'what does the watermark look like ? kind of spooky'), (\"is it bob wire ? i don't think it's barbed wire, no\", 'is the room lit ? yes', 'is there a light source ? no', \"are the zebras' stripes very black or do they look closer to a dark brown ? black\"), ('do you see any buildings ? nope, just grass and trees', 'are there any words on their outfits ? section 26 is on most of the tee shirts', 'is the room dark ? yes', 'what do you mean spooky ? yes')], 'img_features': \n",
      " 0.8899  0.5429  0.9241  ...   1.1822  0.1760  0.1506\n",
      " 3.0966  0.2408  1.2603  ...   0.0101  0.5658  0.6083\n",
      " 0.9914  0.7041  0.3480  ...   1.0365  0.3765  0.1663\n",
      " 0.4256  0.1342  0.8317  ...   0.2769  0.2484  0.0555\n",
      "[torch.FloatTensor of size 4x2048]\n",
      ", 'target': \n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 4]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for idx, batch in enumerate(dataloader_train):\n",
    "    if idx < 1:\n",
    "        print(batch)\n",
    "        idx += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW (\n",
      "  (embeddings): Embedding(28356, 64)\n",
      "  (linear1): Linear (2112 -> 256)\n",
      "  (selu): SELU\n",
      "  (linear2): Linear (256 -> 1)\n",
      "  (sigmoid): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, img_feat_size, output_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim + img_feat_size, output_dim)\n",
    "        self.selu = nn.SELU()\n",
    "        self.linear2 = nn.Linear(output_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_text, input_img_feat, batch_size):\n",
    "        input_text = input_text.view(batch_size, -1)\n",
    "        x = self.embeddings(input_text)\n",
    "        x = torch.sum(x, 1)\n",
    "        x = torch.cat([x, input_img_feat], 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.selu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = CBOW(nwords, 64, 2048, 256).cuda()\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 1 Average loss: 0.0001, Accuracy: 3.0/400000 (0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "        max_len = 0\n",
    "        resulting_text = []\n",
    "        for sentences in text:\n",
    "            resulting_sentences = []\n",
    "            for sentence in sentences:\n",
    "                resulting_sentence = sentence.lower().strip().split(\" \")\n",
    "                max_len = max(max_len, len(resulting_sentence))\n",
    "                resulting_sentences.append([w2i[x] for x in resulting_sentence])\n",
    "            resulting_text.append(resulting_sentences)\n",
    "        resulting_text = [[sentence + ([UNK] * (max_len - len(sentence)))\n",
    "                          for sentence in sentences] for sentences in resulting_text]\n",
    "        return torch.LongTensor(resulting_text)\n",
    "    \n",
    "def train(epoch, dataloader, batch_size = 4, cuda = False):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0.0\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        text_data = preprocess_text(sample['text'])\n",
    "        img_feat = sample['img_features'] \n",
    "        target = sample['target'].float()\n",
    "        if cuda:\n",
    "            text_data, img_feat, target = text_data.cuda(), img_feat.cuda(), target.cuda()\n",
    "        text_data, img_feat, target = Variable(text_data), Variable(img_feat), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text_data, img_feat, batch_size)\n",
    "        loss = F.binary_cross_entropy(output, target, size_average=False)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data[0] # sum up batch loss\n",
    "        pred = output >= 0.5\n",
    "        pred = pred.view(-1) == target.byte()\n",
    "        correct += pred.float().cpu().sum().int().data[0]\n",
    "    train_loss /= len(dataloader.dataset)\n",
    "    print('\\nTrain epoch: {} Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        epoch, train_loss, correct, len(dataloader.dataset),\n",
    "        100.0 * correct / len(dataloader.dataset)))\n",
    "\n",
    "def test(dataloader, batch_size = 1, cuda = False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, sample in enumerate(dataloader_test):\n",
    "        text_data = preprocess_text(sample['text'])\n",
    "        img_feat = sample['img_features'] \n",
    "        target = sample['target'].float()\n",
    "        if cuda:\n",
    "            text_data, img_feat, target = text_data.cuda(), img_feat.cuda(), target.cuda()\n",
    "        text_data, img_feat, target = Variable(text_data, volatile=True), Variable(img_feat, volatile=True), Variable(target)\n",
    "        output = model(text_data, img_feat, batch_size)\n",
    "        loss = F.binary_cross_entropy(output, target, size_average=False)\n",
    "        test_loss += loss.data[0] # sum up batch loss\n",
    "        pred = output >= 0.5\n",
    "        pred = pred.eq(target.byte())\n",
    "        correct += pred.cpu().sum()\n",
    "\n",
    "    test_loss /= len(dataloader_test.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(dataloader.dataset),\n",
    "        100. * correct.float() / len(dataloader.dataset)))\n",
    "\n",
    "import shutil\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    train(epoch, dataloader_train, cuda = True)\n",
    "    prec1 = test(dataloader_val, cuda = True)\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    \"\"\"Evaluate a model on a data set.\"\"\"\n",
    "    correct = 0.0\n",
    "    \n",
    "    for words, tag in data:\n",
    "        lookup_tensor = Variable(torch.LongTensor([words]))\n",
    "        scores = model(lookup_tensor)\n",
    "        predict = scores.data.numpy().argmax(axis=1)[0]\n",
    "\n",
    "        if predict == tag:\n",
    "            correct += 1\n",
    "\n",
    "    return correct, len(data), correct/len(data)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for ITER in range(100):\n",
    "\n",
    "    random.shuffle(train)\n",
    "    train_loss = 0.0\n",
    "    start = time.time()\n",
    "\n",
    "    for words, tag in train:\n",
    "\n",
    "        # forward pass\n",
    "        lookup_tensor = Variable(torch.LongTensor([words]))\n",
    "        scores = model(lookup_tensor)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        target = Variable(torch.LongTensor([tag]))\n",
    "        output = loss(scores, target)\n",
    "        train_loss += output.data[0]\n",
    "\n",
    "        # backward pass\n",
    "        model.zero_grad()\n",
    "        output.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % \n",
    "          (ITER, train_loss/len(train), time.time()-start))\n",
    "\n",
    "    # evaluate\n",
    "    _, _, acc = evaluate(model, dev)\n",
    "    print(\"iter %r: test acc=%.4f\" % (ITER, acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
